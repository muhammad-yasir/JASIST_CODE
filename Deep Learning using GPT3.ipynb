{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import uuid\n",
    "openai.api_key = \"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\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/Google Reviews.csv')  ## Google review dataset\n",
    "#df = pd.read_csv('./Data/Play Store App reviews.csv')  ## App reviews from Google Play Storedf = df[['Review_Text','Final Coding']]\n",
    "X_data = df[['Review_Text']]\n",
    "y_data = df[['Final Coding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state= 42)\n",
    "x_rus ,y_rus = rus.fit_resample(X_data,y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_rus, y_rus, test_size=0.3, random_state=777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_train)\n",
    "train_df['completion'] = y_train\n",
    "\n",
    "eval_df = pd.DataFrame(X_test)\n",
    "eval_df['completion'] = y_test\n",
    "\n",
    "train_df.rename(columns={'Review_Text':'prompt'},inplace=1)\n",
    "eval_df.rename(columns={'Review_Text':'prompt'},inplace=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(\"train.jsonl\",orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 14000 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 95 duplicated prompt-completion sets. These are rows: [1056, 1191, 1667, 2159, 2610, 3139, 3278, 3324, 3708, 3946, 4014, 4375, 4454, 4643, 5154, 5253, 5452, 5990, 6201, 6291, 6351, 6919, 7081, 7379, 7823, 7947, 8078, 8174, 8307, 8505, 8628, 8680, 8708, 8860, 8864, 8914, 8941, 8953, 9100, 9110, 9127, 9187, 9257, 9272, 9468, 9722, 9768, 9901, 9929, 10112, 10179, 10243, 10501, 10530, 10630, 10643, 10697, 10764, 10783, 10986, 11264, 11323, 11366, 11372, 11572, 11573, 11616, 11660, 11798, 11916, 11960, 12059, 12199, 12239, 12369, 12438, 12583, 12667, 12787, 12817, 12841, 12896, 13049, 13231, 13272, 13405, 13478, 13646, 13658, 13666, 13768, 13875, 13907, 13934, 13975]\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 95 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `train_prepared_train.jsonl` and `train_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"train_prepared_train.jsonl\" -v \"train_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" 1\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
      "Once your model starts training, it'll approximately take 5.6 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasir Muhammad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\validators.py:215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[\"prompt\"] += suffix\n",
      "C:\\Users\\Yasir Muhammad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\validators.py:414: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[\"completion\"] = x[\"completion\"].apply(\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f train.jsonl -q    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!openai -k \"Your_API_KEY\" api fine_tunes.create -t \"training_dataset_oversample_google_prepared.jsonl\" --model ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 21:25:27] Created fine-tune: ft-M6OzoH80NLjn8pLCmv7WEOl8\n",
      "[2022-03-02 21:25:36] Fine-tune costs $6.20\n",
      "[2022-03-02 21:25:37] Fine-tune enqueued. Queue number: 0\n",
      "[2022-03-02 21:25:39] Fine-tune started\n",
      "[2022-03-02 21:36:02] Completed epoch 1/4\n",
      "[2022-03-02 21:45:48] Completed epoch 2/4\n",
      "[2022-03-02 21:55:31] Completed epoch 3/4\n",
      "[2022-03-02 22:05:11] Completed epoch 4/4\n",
      "[2022-03-02 22:05:40] Uploaded model: curie:ft-personal-2022-03-02-09-05-38\n",
      "[2022-03-02 22:05:43] Uploaded result file: file-3r7yi9uk1gkDy6rYwCbmNMla\n",
      "[2022-03-02 22:05:43] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-personal-2022-03-02-09-05-38 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai -k \"Your_API_KEY\" api fine_tunes.follow -i ft-M6OzoH80NLjn8pLCmv7WEOl8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_predict = []\n",
    "ft_model = 'Uploaded model name enter here'\n",
    "\n",
    "for row,item in test.iterrows():\n",
    "    res = openai.Completion.create(model= ft_model,prompt=item['prompt'],max_tokens=1,temperature=0 )\n",
    "    gpt_predict.append(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if x == ' 1' else 0 for x in gpt_predict]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is \", accuracy_score(test_df['completion'],y_pred))\n",
    "print(\"Precision is \",precision_score(test_df['completion'],y_pred))\n",
    "print(\"Recall is \",recall_score(test_df['completion'],y_pred))\n",
    "print(\"F1-score is\",f1_score(test_df['completion'],y_pred))\n",
    "print(\"Mathew corrcoef is \",matthews_corrcoef(test_df['completion'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919b6843753584bb5a6e833a429d8176522842f3c8b8fdcd54d0bec6bffbd095"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
